{"cells":[{"cell_type":"code","execution_count":42,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-15T12:06:49.966389Z","iopub.status.busy":"2022-09-15T12:06:49.965936Z","iopub.status.idle":"2022-09-15T12:06:49.982308Z","shell.execute_reply":"2022-09-15T12:06:49.981352Z","shell.execute_reply.started":"2022-09-15T12:06:49.966352Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, we are going to build the model. Before going through this, check EDA of this datase\n","\n","https://www.kaggle.com/code/naarku30/graduate-admissions-eda"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:49.985218Z","iopub.status.busy":"2022-09-15T12:06:49.984705Z","iopub.status.idle":"2022-09-15T12:06:50.010128Z","shell.execute_reply":"2022-09-15T12:06:50.008734Z","shell.execute_reply.started":"2022-09-15T12:06:49.985176Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>GRE Score</th>\n","      <th>TOEFL Score</th>\n","      <th>University Rating</th>\n","      <th>SOP</th>\n","      <th>LOR</th>\n","      <th>CGPA</th>\n","      <th>Research</th>\n","      <th>Chance of Admit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>337</td>\n","      <td>118</td>\n","      <td>4</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>9.65</td>\n","      <td>1</td>\n","      <td>0.92</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>324</td>\n","      <td>107</td>\n","      <td>4</td>\n","      <td>4.0</td>\n","      <td>4.5</td>\n","      <td>8.87</td>\n","      <td>1</td>\n","      <td>0.76</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n","0        337          118                  4  4.5   4.5  9.65         1   \n","1        324          107                  4  4.0   4.5  8.87         1   \n","\n","   Chance of Admit   \n","0              0.92  \n","1              0.76  "]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('admission_data.csv')\n","df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["There are many regression algorithms, we need to find the best performing model"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:50.013313Z","iopub.status.busy":"2022-09-15T12:06:50.012824Z","iopub.status.idle":"2022-09-15T12:06:50.023744Z","shell.execute_reply":"2022-09-15T12:06:50.022064Z","shell.execute_reply.started":"2022-09-15T12:06:50.013250Z"},"trusted":true},"outputs":[],"source":["#Train test split\n","from sklearn.model_selection import train_test_split\n","\n","X = df.drop(['Chance of Admit '], axis=1)\n","y = df['Chance of Admit ']\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["Here GRE is out of 340, TOEFL is out of 120, University Rating is specified in 5 values. Here, every feature is in differnert dimesnion. So to convert everything into one unit, we use Standard Scaler. So that we can reach the global minimum easily."]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:50.026580Z","iopub.status.busy":"2022-09-15T12:06:50.025735Z","iopub.status.idle":"2022-09-15T12:06:50.047960Z","shell.execute_reply":"2022-09-15T12:06:50.045989Z","shell.execute_reply.started":"2022-09-15T12:06:50.026528Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["# Saving the scaler \n","\n","import pickle\n","pickle.dump(scaler,open('scaling.pkl','wb'))"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:50.052439Z","iopub.status.busy":"2022-09-15T12:06:50.051584Z","iopub.status.idle":"2022-09-15T12:06:51.723798Z","shell.execute_reply":"2022-09-15T12:06:51.722370Z","shell.execute_reply.started":"2022-09-15T12:06:50.052388Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Results...\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>MAE</th>\n","      <th>MSE</th>\n","      <th>RMSE</th>\n","      <th>R2 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTree</td>\n","      <td>0.059200</td>\n","      <td>0.006156</td>\n","      <td>0.078460</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Linear Regression</td>\n","      <td>0.034729</td>\n","      <td>0.002002</td>\n","      <td>0.044743</td>\n","      <td>0.803471</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RandomForest</td>\n","      <td>0.038543</td>\n","      <td>0.002977</td>\n","      <td>0.054566</td>\n","      <td>0.965251</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>KNeighbours</td>\n","      <td>0.053650</td>\n","      <td>0.004860</td>\n","      <td>0.069712</td>\n","      <td>0.902750</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SVM</td>\n","      <td>0.047529</td>\n","      <td>0.003748</td>\n","      <td>0.061222</td>\n","      <td>0.772084</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>AdaBoostClassifier</td>\n","      <td>0.038415</td>\n","      <td>0.002694</td>\n","      <td>0.051903</td>\n","      <td>0.797040</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>GradientBoostingClassifier</td>\n","      <td>0.038044</td>\n","      <td>0.002980</td>\n","      <td>0.054588</td>\n","      <td>0.909321</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Xgboost</td>\n","      <td>0.046966</td>\n","      <td>0.004109</td>\n","      <td>0.064099</td>\n","      <td>0.999775</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CatBoost</td>\n","      <td>0.039499</td>\n","      <td>0.003112</td>\n","      <td>0.055784</td>\n","      <td>0.976357</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Lasso</td>\n","      <td>0.112222</td>\n","      <td>0.018292</td>\n","      <td>0.135246</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Ridge</td>\n","      <td>0.034734</td>\n","      <td>0.002000</td>\n","      <td>0.044721</td>\n","      <td>0.803466</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>BayesianRidge</td>\n","      <td>0.034782</td>\n","      <td>0.001995</td>\n","      <td>0.044670</td>\n","      <td>0.803371</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>ElasticNet</td>\n","      <td>0.112222</td>\n","      <td>0.018292</td>\n","      <td>0.135246</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>HuberRegressor</td>\n","      <td>0.036651</td>\n","      <td>0.002374</td>\n","      <td>0.048720</td>\n","      <td>0.797698</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Model       MAE       MSE      RMSE  R2 Score\n","0                 DecisionTree  0.059200  0.006156  0.078460  1.000000\n","1            Linear Regression  0.034729  0.002002  0.044743  0.803471\n","2                 RandomForest  0.038543  0.002977  0.054566  0.965251\n","3                  KNeighbours  0.053650  0.004860  0.069712  0.902750\n","4                          SVM  0.047529  0.003748  0.061222  0.772084\n","5           AdaBoostClassifier  0.038415  0.002694  0.051903  0.797040\n","6   GradientBoostingClassifier  0.038044  0.002980  0.054588  0.909321\n","7                      Xgboost  0.046966  0.004109  0.064099  0.999775\n","8                     CatBoost  0.039499  0.003112  0.055784  0.976357\n","9                        Lasso  0.112222  0.018292  0.135246  0.000000\n","10                       Ridge  0.034734  0.002000  0.044721  0.803466\n","11               BayesianRidge  0.034782  0.001995  0.044670  0.803371\n","12                  ElasticNet  0.112222  0.018292  0.135246  0.000000\n","13              HuberRegressor  0.036651  0.002374  0.048720  0.797698"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from xgboost import XGBRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.linear_model import Lasso,Ridge,BayesianRidge,ElasticNet,HuberRegressor,LinearRegression,LogisticRegression,SGDRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","models = [['DecisionTree',DecisionTreeRegressor()],\n","           ['Linear Regression', LinearRegression()],\n","           ['RandomForest',RandomForestRegressor()],\n","           ['KNeighbours', KNeighborsRegressor(n_neighbors = 2)],\n","           ['SVM', SVR()],\n","           ['AdaBoostClassifier', AdaBoostRegressor()],\n","           ['GradientBoostingClassifier', GradientBoostingRegressor()],\n","           ['Xgboost', XGBRegressor()],\n","           ['CatBoost', CatBoostRegressor(logging_level='Silent')],\n","           ['Lasso', Lasso()],\n","           ['Ridge', Ridge()],\n","           ['BayesianRidge', BayesianRidge()],\n","           ['ElasticNet', ElasticNet()],\n","           ['HuberRegressor', HuberRegressor()]]\n","\n","print(\"Results...\")\n","\n","kpis = []\n","\n","for name,model in models:\n","    model = model\n","    model.fit(X_train, y_train)\n","    pred = model.predict(X_test)\n","    mae = mean_absolute_error(y_test, pred)\n","    mse = mean_squared_error(y_test, pred)\n","    rmse = np.sqrt(mse)\n","    r2_score = model.score(X_train,y_train)\n","    kpis.append([name,mae,mse,rmse,r2_score])\n","    \n","kpi = pd.DataFrame(kpis,columns=['Model','MAE','MSE','RMSE','R2 Score'])\n","kpi"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:51.725854Z","iopub.status.busy":"2022-09-15T12:06:51.725485Z","iopub.status.idle":"2022-09-15T12:06:51.744162Z","shell.execute_reply":"2022-09-15T12:06:51.742016Z","shell.execute_reply.started":"2022-09-15T12:06:51.725821Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>MAE</th>\n","      <th>MSE</th>\n","      <th>RMSE</th>\n","      <th>R2 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11</th>\n","      <td>BayesianRidge</td>\n","      <td>0.034782</td>\n","      <td>0.001995</td>\n","      <td>0.044670</td>\n","      <td>0.803371</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Ridge</td>\n","      <td>0.034734</td>\n","      <td>0.002000</td>\n","      <td>0.044721</td>\n","      <td>0.803466</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Linear Regression</td>\n","      <td>0.034729</td>\n","      <td>0.002002</td>\n","      <td>0.044743</td>\n","      <td>0.803471</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>HuberRegressor</td>\n","      <td>0.036651</td>\n","      <td>0.002374</td>\n","      <td>0.048720</td>\n","      <td>0.797698</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>AdaBoostClassifier</td>\n","      <td>0.038415</td>\n","      <td>0.002694</td>\n","      <td>0.051903</td>\n","      <td>0.797040</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RandomForest</td>\n","      <td>0.038543</td>\n","      <td>0.002977</td>\n","      <td>0.054566</td>\n","      <td>0.965251</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>GradientBoostingClassifier</td>\n","      <td>0.038044</td>\n","      <td>0.002980</td>\n","      <td>0.054588</td>\n","      <td>0.909321</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CatBoost</td>\n","      <td>0.039499</td>\n","      <td>0.003112</td>\n","      <td>0.055784</td>\n","      <td>0.976357</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SVM</td>\n","      <td>0.047529</td>\n","      <td>0.003748</td>\n","      <td>0.061222</td>\n","      <td>0.772084</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Xgboost</td>\n","      <td>0.046966</td>\n","      <td>0.004109</td>\n","      <td>0.064099</td>\n","      <td>0.999775</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>KNeighbours</td>\n","      <td>0.053650</td>\n","      <td>0.004860</td>\n","      <td>0.069712</td>\n","      <td>0.902750</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>DecisionTree</td>\n","      <td>0.059200</td>\n","      <td>0.006156</td>\n","      <td>0.078460</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Lasso</td>\n","      <td>0.112222</td>\n","      <td>0.018292</td>\n","      <td>0.135246</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>ElasticNet</td>\n","      <td>0.112222</td>\n","      <td>0.018292</td>\n","      <td>0.135246</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         Model       MAE       MSE      RMSE  R2 Score\n","11               BayesianRidge  0.034782  0.001995  0.044670  0.803371\n","10                       Ridge  0.034734  0.002000  0.044721  0.803466\n","1            Linear Regression  0.034729  0.002002  0.044743  0.803471\n","13              HuberRegressor  0.036651  0.002374  0.048720  0.797698\n","5           AdaBoostClassifier  0.038415  0.002694  0.051903  0.797040\n","2                 RandomForest  0.038543  0.002977  0.054566  0.965251\n","6   GradientBoostingClassifier  0.038044  0.002980  0.054588  0.909321\n","8                     CatBoost  0.039499  0.003112  0.055784  0.976357\n","4                          SVM  0.047529  0.003748  0.061222  0.772084\n","7                      Xgboost  0.046966  0.004109  0.064099  0.999775\n","3                  KNeighbours  0.053650  0.004860  0.069712  0.902750\n","0                 DecisionTree  0.059200  0.006156  0.078460  1.000000\n","9                        Lasso  0.112222  0.018292  0.135246  0.000000\n","12                  ElasticNet  0.112222  0.018292  0.135246  0.000000"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["kpi.sort_values('RMSE',ascending=True)"]},{"cell_type":"markdown","metadata":{},"source":["We have scored the test data using various regression models. So, we continue with Linear Regression, Random Forest and Ridge. I only selected these because I have knowledge on these models and they are performing good\n"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:51.746787Z","iopub.status.busy":"2022-09-15T12:06:51.746239Z","iopub.status.idle":"2022-09-15T12:06:51.760061Z","shell.execute_reply":"2022-09-15T12:06:51.758996Z","shell.execute_reply.started":"2022-09-15T12:06:51.746737Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Root Mean Squared error: 0.04474312524349167\n"]}],"source":["#Linear Regression Model\n","\n","lr_model = LinearRegression()\n","lr_model.fit(X_train,y_train)\n","pred = lr_model.predict(X_test)\n","mse = mean_squared_error(y_test, pred)\n","rmse = np.sqrt(mse)\n","print(\"Root Mean Squared error:\", rmse)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:51.762152Z","iopub.status.busy":"2022-09-15T12:06:51.761696Z","iopub.status.idle":"2022-09-15T12:06:52.014050Z","shell.execute_reply":"2022-09-15T12:06:52.011877Z","shell.execute_reply.started":"2022-09-15T12:06:51.762081Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Root Mean Squared error: 0.05281467977750127\n"]}],"source":["#Random Forest Regressor Model\n","\n","rf_model = RandomForestRegressor()\n","rf_model.fit(X_train,y_train)\n","pred = rf_model.predict(X_test)\n","mse = mean_squared_error(y_test, pred)\n","rmse = np.sqrt(mse)\n","print(\"Root Mean Squared error:\", rmse)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:52.017278Z","iopub.status.busy":"2022-09-15T12:06:52.016559Z","iopub.status.idle":"2022-09-15T12:06:52.028007Z","shell.execute_reply":"2022-09-15T12:06:52.026656Z","shell.execute_reply.started":"2022-09-15T12:06:52.017211Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Ridge Model score: 0.8034661029324273\n","Root Mean Squared error: 0.04472093099187097\n"]}],"source":["#Ridge Model\n","\n","ridge_model = Ridge()\n","ridge_model.fit(X_train,y_train)\n","print(\"Ridge Model score:\", ridge_model.score(X_train, y_train))\n","pred = ridge_model.predict(X_test)\n","mse = mean_squared_error(y_test, pred)\n","rmse = np.sqrt(mse)\n","print(\"Root Mean Squared error:\", rmse)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.76314891 0.63403983 0.80196708 0.75237451 0.87030984 0.87650853\n"," 0.81908165 0.81853568 0.91871869 0.87566439]\n","Mean: 0.8130349102443176\n"]}],"source":["#K Fold Cross Validation\n","\n","from sklearn.model_selection import KFold\n","model = Ridge()\n","kfold_validation = KFold(10)\n","\n","from sklearn.model_selection import cross_val_score\n","results = cross_val_score(model, X, y, cv=kfold_validation)\n","print(results)\n","\n","print(\"Mean:\", np.mean(results))"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["# Saving the ridge model\n","\n","pickle.dump(ridge_model,open('model.pkl','wb'))"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions"]},{"cell_type":"markdown","metadata":{},"source":["From the EDA we have observed many points. Let's take some assumptions and predict for the new data.\n","We know, to get higher chances of Admit\n","* GRE: >310\n","* TOEFL: >105\n","* CGPA: >8.5\n","* University Rating: >=4\n","* Research: 1"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:52.031013Z","iopub.status.busy":"2022-09-15T12:06:52.030076Z","iopub.status.idle":"2022-09-15T12:06:52.045590Z","shell.execute_reply":"2022-09-15T12:06:52.044333Z","shell.execute_reply.started":"2022-09-15T12:06:52.030969Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression prediction:  [0.68449772]\n","Random Forest prediction:  [0.68449772]\n","Ridge prediction: [0.68527023]\n"]}],"source":["#Test 1\n","t1 = [319,107, 4, 4, 4, 8.1, 0]\n","\n","print(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t1).reshape(1,-1))))\n","print(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t1).reshape(1,-1))))\n","print(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t1).reshape(1,-1))))"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:52.049500Z","iopub.status.busy":"2022-09-15T12:06:52.048994Z","iopub.status.idle":"2022-09-15T12:06:52.064526Z","shell.execute_reply":"2022-09-15T12:06:52.062706Z","shell.execute_reply.started":"2022-09-15T12:06:52.049461Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression prediction:  [0.75200375]\n","Random Forest prediction:  [0.75200375]\n","Ridge prediction: [0.75210039]\n"]}],"source":["#Test2\n","t2 = [319,107, 4, 4, 4, 8.7, 0]\n","\n","print(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\n","print(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\n","print(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:52.067178Z","iopub.status.busy":"2022-09-15T12:06:52.066559Z","iopub.status.idle":"2022-09-15T12:06:52.078151Z","shell.execute_reply":"2022-09-15T12:06:52.076670Z","shell.execute_reply.started":"2022-09-15T12:06:52.067140Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression prediction:  [0.77703111]\n","Random Forest prediction:  [0.77703111]\n","Ridge prediction: [0.77712892]\n"]}],"source":["#Test2\n","t2 = [319,107, 4, 4, 4, 8.7, 1]\n","\n","print(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\n","print(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\n","print(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:52.081632Z","iopub.status.busy":"2022-09-15T12:06:52.080378Z","iopub.status.idle":"2022-09-15T12:06:52.097245Z","shell.execute_reply":"2022-09-15T12:06:52.094330Z","shell.execute_reply.started":"2022-09-15T12:06:52.081572Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression prediction:  [0.85578814]\n","Random Forest prediction:  [0.85578814]\n","Ridge prediction: [0.85509744]\n"]}],"source":["#Test2\n","t2 = [319,107, 4, 4, 4, 9.4, 1]\n","\n","print(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\n","print(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\n","print(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))"]},{"cell_type":"markdown","metadata":{},"source":["Lot of dependency on CGPA"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-09-15T12:06:52.101482Z","iopub.status.busy":"2022-09-15T12:06:52.099849Z","iopub.status.idle":"2022-09-15T12:06:52.114995Z","shell.execute_reply":"2022-09-15T12:06:52.113511Z","shell.execute_reply.started":"2022-09-15T12:06:52.101344Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear Regression prediction:  [0.90677949]\n","Random Forest prediction:  [0.90677949]\n","Ridge prediction: [0.90663372]\n"]}],"source":["#Test3\n","t3 = [332,114, 5, 4, 4, 9.4, 1]\n","\n","print(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t3).reshape(1,-1))))\n","print(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t3).reshape(1,-1))))\n","print(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t3).reshape(1,-1))))"]},{"cell_type":"markdown","metadata":{},"source":["Applying K - FOLD Cross Validation"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["#Function for Ridge to test the Cross Validation\n","\n","def ridge(X_train, X_test, y_train, y_test):\n","    ridge_model = Ridge()\n","    ridge_model.fit(X_train,y_train)\n","    print(\"Ridge Model score:\", ridge_model.score(X_train, y_train))\n","    pred = ridge_model.predict(X_test)\n","    mse = mean_squared_error(y_test, pred)\n","    rmse = np.sqrt(mse)\n","    print(\"Root Mean Squared error:\", rmse)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ridge Model score: 0.8320461610880847\n","Root Mean Squared error: 0.06394657764105446\n","Ridge Model score: 0.8214595570552597\n","Root Mean Squared error: 0.05888978209684229\n"]}],"source":["#Hold Out Validation - Train test split\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20,random_state=0)\n","ridge(X_train, X_test, y_train, y_test)\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20,random_state=1)\n","ridge(X_train, X_test, y_train, y_test)\n","\n","\n","#Having different RMSE for different rnadom_state. We need to perform K-Fold\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.76314891 0.63403983 0.80196708 0.75237451 0.87030984 0.87650853\n"," 0.81908165 0.81853568 0.91871869 0.87566439]\n","Mean: 0.8130349102443176\n"]}],"source":["#K Fold Cross Validation\n","\n","from sklearn.model_selection import KFold\n","model = ridge_model\n","kfold_validation = KFold(10)\n","\n","from sklearn.model_selection import cross_val_score\n","results = cross_val_score(model, X, y, cv=kfold_validation)\n","print(results)\n","\n","print(\"Mean:\", np.mean(results))"]},{"cell_type":"markdown","metadata":{},"source":["We can convey this as the average of accuracy occured on 10 folds. So, the minimum accuracy I have obtained is 0.63 and maximum accuracy I have obtained is 0.91 and average of accuracy is 0.81"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mEmpty\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18708/1132359406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msfold_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msfold_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 250\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    831\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                 \u001b[0mislice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 250\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[0;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n","\u001b[1;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."]}],"source":["#Stratified Cross Validation - apply on classification\n","\n","from sklearn.model_selection import StratifiedKFold\n","model = ridge_model\n","sfold_validation = StratifiedKFold(10)\n","\n","results = cross_val_score(model, X, y, cv=sfold_validation)\n","print(results)\n","\n","print(\"Mean:\", np.mean(results))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n"," nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n","Mean: nan\n"]}],"source":["#Leave one Out Cross validation\n","\n","from sklearn.model_selection import LeaveOneOut\n","leaveoneout = LeaveOneOut()\n","results = cross_val_score(model, X,y,cv=leaveoneout)\n","print(results)\n","\n","print(\"Mean:\", np.mean(results))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.77339262 0.83910477 0.81324415 0.82358635 0.82899097 0.77070643\n"," 0.84017666 0.85522962 0.78164414 0.84722017]\n","Mean: 0.8173295883228029\n"]}],"source":["#Shuffle split - multiple iterations of train test split similar to Kfold but based on test size\n","from sklearn.model_selection import ShuffleSplit\n","split = ShuffleSplit(n_splits=10, test_size=0.3)\n","results = cross_val_score(model, X,y, cv=split)\n","print(results)\n","\n","print(\"Mean:\", np.mean(results))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"}}},"nbformat":4,"nbformat_minor":4}
