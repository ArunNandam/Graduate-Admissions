{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-15T12:06:49.965936Z","iopub.execute_input":"2022-09-15T12:06:49.966389Z","iopub.status.idle":"2022-09-15T12:06:49.982308Z","shell.execute_reply.started":"2022-09-15T12:06:49.966352Z","shell.execute_reply":"2022-09-15T12:06:49.981352Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"/kaggle/input/graduates-admission-prediction/admission_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this notebook, we are going to build the model. Before going through this, check EDA of this datase\n\nhttps://www.kaggle.com/code/naarku30/graduate-admissions-eda","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/graduates-admission-prediction/admission_data.csv')\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:49.984705Z","iopub.execute_input":"2022-09-15T12:06:49.985218Z","iopub.status.idle":"2022-09-15T12:06:50.010128Z","shell.execute_reply.started":"2022-09-15T12:06:49.985176Z","shell.execute_reply":"2022-09-15T12:06:50.008734Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n0        337          118                  4  4.5   4.5  9.65         1   \n1        324          107                  4  4.0   4.5  8.87         1   \n\n   Chance of Admit   \n0              0.92  \n1              0.76  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"There are many regression algorithms, we need to find the best performing model","metadata":{}},{"cell_type":"code","source":"#Train test split\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop(['Chance of Admit '], axis=1)\ny = df['Chance of Admit ']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:50.012824Z","iopub.execute_input":"2022-09-15T12:06:50.013313Z","iopub.status.idle":"2022-09-15T12:06:50.023744Z","shell.execute_reply.started":"2022-09-15T12:06:50.013250Z","shell.execute_reply":"2022-09-15T12:06:50.022064Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"Here GRE is out of 340, TOEFL is out of 120, University Rating is specified in 5 values. Here, every feature is in differnert dimesnion. So to convert everything into one unit, we use Standard Scaler. So that we can reach the global minimum easily.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:50.025735Z","iopub.execute_input":"2022-09-15T12:06:50.026580Z","iopub.status.idle":"2022-09-15T12:06:50.047960Z","shell.execute_reply.started":"2022-09-15T12:06:50.026528Z","shell.execute_reply":"2022-09-15T12:06:50.045989Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import Lasso,Ridge,BayesianRidge,ElasticNet,HuberRegressor,LinearRegression,LogisticRegression,SGDRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nmodels = [['DecisionTree',DecisionTreeRegressor()],\n           ['Linear Regression', LinearRegression()],\n           ['RandomForest',RandomForestRegressor()],\n           ['KNeighbours', KNeighborsRegressor(n_neighbors = 2)],\n           ['SVM', SVR()],\n           ['AdaBoostClassifier', AdaBoostRegressor()],\n           ['GradientBoostingClassifier', GradientBoostingRegressor()],\n           ['Xgboost', XGBRegressor()],\n           ['CatBoost', CatBoostRegressor(logging_level='Silent')],\n           ['Lasso', Lasso()],\n           ['Ridge', Ridge()],\n           ['BayesianRidge', BayesianRidge()],\n           ['ElasticNet', ElasticNet()],\n           ['HuberRegressor', HuberRegressor()]]\n\nprint(\"Results...\")\n\nkpis = []\n\nfor name,model in models:\n    model = model\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    mae = mean_absolute_error(y_test, pred)\n    mse = mean_squared_error(y_test, pred)\n    rmse = np.sqrt(mse)\n    r2_score = model.score(X_train,y_train)\n    kpis.append([name,mae,mse,rmse,r2_score])\n    \nkpi = pd.DataFrame(kpis,columns=['Model','MAE','MSE','RMSE','R2 Score'])\nkpi","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:50.051584Z","iopub.execute_input":"2022-09-15T12:06:50.052439Z","iopub.status.idle":"2022-09-15T12:06:51.723798Z","shell.execute_reply.started":"2022-09-15T12:06:50.052388Z","shell.execute_reply":"2022-09-15T12:06:51.722370Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Results...\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"                         Model       MAE       MSE      RMSE  R2 Score\n0                 DecisionTree  0.062000  0.006758  0.082207  1.000000\n1            Linear Regression  0.034729  0.002002  0.044743  0.803471\n2                 RandomForest  0.038122  0.002834  0.053234  0.965897\n3                  KNeighbours  0.053650  0.004860  0.069712  0.902750\n4                          SVM  0.047529  0.003748  0.061222  0.772084\n5           AdaBoostClassifier  0.038512  0.002675  0.051722  0.810854\n6   GradientBoostingClassifier  0.038058  0.002957  0.054381  0.909321\n7                      Xgboost  0.046966  0.004109  0.064099  0.999775\n8                     CatBoost  0.039499  0.003112  0.055784  0.976357\n9                        Lasso  0.112222  0.018292  0.135246  0.000000\n10                       Ridge  0.034734  0.002000  0.044721  0.803466\n11               BayesianRidge  0.034782  0.001995  0.044670  0.803371\n12                  ElasticNet  0.112222  0.018292  0.135246  0.000000\n13              HuberRegressor  0.036651  0.002374  0.048720  0.797698","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>R2 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DecisionTree</td>\n      <td>0.062000</td>\n      <td>0.006758</td>\n      <td>0.082207</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Linear Regression</td>\n      <td>0.034729</td>\n      <td>0.002002</td>\n      <td>0.044743</td>\n      <td>0.803471</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>0.038122</td>\n      <td>0.002834</td>\n      <td>0.053234</td>\n      <td>0.965897</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighbours</td>\n      <td>0.053650</td>\n      <td>0.004860</td>\n      <td>0.069712</td>\n      <td>0.902750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVM</td>\n      <td>0.047529</td>\n      <td>0.003748</td>\n      <td>0.061222</td>\n      <td>0.772084</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AdaBoostClassifier</td>\n      <td>0.038512</td>\n      <td>0.002675</td>\n      <td>0.051722</td>\n      <td>0.810854</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.038058</td>\n      <td>0.002957</td>\n      <td>0.054381</td>\n      <td>0.909321</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Xgboost</td>\n      <td>0.046966</td>\n      <td>0.004109</td>\n      <td>0.064099</td>\n      <td>0.999775</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CatBoost</td>\n      <td>0.039499</td>\n      <td>0.003112</td>\n      <td>0.055784</td>\n      <td>0.976357</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Lasso</td>\n      <td>0.112222</td>\n      <td>0.018292</td>\n      <td>0.135246</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Ridge</td>\n      <td>0.034734</td>\n      <td>0.002000</td>\n      <td>0.044721</td>\n      <td>0.803466</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BayesianRidge</td>\n      <td>0.034782</td>\n      <td>0.001995</td>\n      <td>0.044670</td>\n      <td>0.803371</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ElasticNet</td>\n      <td>0.112222</td>\n      <td>0.018292</td>\n      <td>0.135246</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>HuberRegressor</td>\n      <td>0.036651</td>\n      <td>0.002374</td>\n      <td>0.048720</td>\n      <td>0.797698</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"kpi.sort_values('RMSE',ascending=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:51.725485Z","iopub.execute_input":"2022-09-15T12:06:51.725854Z","iopub.status.idle":"2022-09-15T12:06:51.744162Z","shell.execute_reply.started":"2022-09-15T12:06:51.725821Z","shell.execute_reply":"2022-09-15T12:06:51.742016Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"                         Model       MAE       MSE      RMSE  R2 Score\n11               BayesianRidge  0.034782  0.001995  0.044670  0.803371\n10                       Ridge  0.034734  0.002000  0.044721  0.803466\n1            Linear Regression  0.034729  0.002002  0.044743  0.803471\n13              HuberRegressor  0.036651  0.002374  0.048720  0.797698\n5           AdaBoostClassifier  0.038512  0.002675  0.051722  0.810854\n2                 RandomForest  0.038122  0.002834  0.053234  0.965897\n6   GradientBoostingClassifier  0.038058  0.002957  0.054381  0.909321\n8                     CatBoost  0.039499  0.003112  0.055784  0.976357\n4                          SVM  0.047529  0.003748  0.061222  0.772084\n7                      Xgboost  0.046966  0.004109  0.064099  0.999775\n3                  KNeighbours  0.053650  0.004860  0.069712  0.902750\n0                 DecisionTree  0.062000  0.006758  0.082207  1.000000\n9                        Lasso  0.112222  0.018292  0.135246  0.000000\n12                  ElasticNet  0.112222  0.018292  0.135246  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>MSE</th>\n      <th>RMSE</th>\n      <th>R2 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>BayesianRidge</td>\n      <td>0.034782</td>\n      <td>0.001995</td>\n      <td>0.044670</td>\n      <td>0.803371</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Ridge</td>\n      <td>0.034734</td>\n      <td>0.002000</td>\n      <td>0.044721</td>\n      <td>0.803466</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Linear Regression</td>\n      <td>0.034729</td>\n      <td>0.002002</td>\n      <td>0.044743</td>\n      <td>0.803471</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>HuberRegressor</td>\n      <td>0.036651</td>\n      <td>0.002374</td>\n      <td>0.048720</td>\n      <td>0.797698</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AdaBoostClassifier</td>\n      <td>0.038512</td>\n      <td>0.002675</td>\n      <td>0.051722</td>\n      <td>0.810854</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForest</td>\n      <td>0.038122</td>\n      <td>0.002834</td>\n      <td>0.053234</td>\n      <td>0.965897</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.038058</td>\n      <td>0.002957</td>\n      <td>0.054381</td>\n      <td>0.909321</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CatBoost</td>\n      <td>0.039499</td>\n      <td>0.003112</td>\n      <td>0.055784</td>\n      <td>0.976357</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SVM</td>\n      <td>0.047529</td>\n      <td>0.003748</td>\n      <td>0.061222</td>\n      <td>0.772084</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Xgboost</td>\n      <td>0.046966</td>\n      <td>0.004109</td>\n      <td>0.064099</td>\n      <td>0.999775</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KNeighbours</td>\n      <td>0.053650</td>\n      <td>0.004860</td>\n      <td>0.069712</td>\n      <td>0.902750</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>DecisionTree</td>\n      <td>0.062000</td>\n      <td>0.006758</td>\n      <td>0.082207</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Lasso</td>\n      <td>0.112222</td>\n      <td>0.018292</td>\n      <td>0.135246</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ElasticNet</td>\n      <td>0.112222</td>\n      <td>0.018292</td>\n      <td>0.135246</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We have scored the test data using various regression models. So, we continue with Linear Regression, Random Forest and Ridge. I only selected these because I have knowledge on these models and they are performing good\n","metadata":{}},{"cell_type":"code","source":"#Linear Regression Model\n\nlr_model = LinearRegression()\nlr_model.fit(X_train,y_train)\npred = lr_model.predict(X_test)\nmse = mean_squared_error(y_test, pred)\nrmse = np.sqrt(mse)\nprint(\"Root Mean Squared error:\", rmse)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:51.746239Z","iopub.execute_input":"2022-09-15T12:06:51.746787Z","iopub.status.idle":"2022-09-15T12:06:51.760061Z","shell.execute_reply.started":"2022-09-15T12:06:51.746737Z","shell.execute_reply":"2022-09-15T12:06:51.758996Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Root Mean Squared error: 0.04474312524349171\n","output_type":"stream"}]},{"cell_type":"code","source":"#Random Forest Regressor Model\n\nrf_model = RandomForestRegressor()\nrf_model.fit(X_train,y_train)\npred = rf_model.predict(X_test)\nmse = mean_squared_error(y_test, pred)\nrmse = np.sqrt(mse)\nprint(\"Root Mean Squared error:\", rmse)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:51.761696Z","iopub.execute_input":"2022-09-15T12:06:51.762152Z","iopub.status.idle":"2022-09-15T12:06:52.014050Z","shell.execute_reply.started":"2022-09-15T12:06:51.762081Z","shell.execute_reply":"2022-09-15T12:06:52.011877Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Root Mean Squared error: 0.05167246075038426\n","output_type":"stream"}]},{"cell_type":"code","source":"#Ridge Model\n\nridge_model = Ridge()\nridge_model.fit(X_train,y_train)\npred = ridge_model.predict(X_test)\nmse = mean_squared_error(y_test, pred)\nrmse = np.sqrt(mse)\nprint(\"Root Mean Squared error:\", rmse)","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:52.016559Z","iopub.execute_input":"2022-09-15T12:06:52.017278Z","iopub.status.idle":"2022-09-15T12:06:52.028007Z","shell.execute_reply.started":"2022-09-15T12:06:52.017211Z","shell.execute_reply":"2022-09-15T12:06:52.026656Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Root Mean Squared error: 0.044720930991870925\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"markdown","source":"From the EDA we have observed many points. Let's take some assumptions and predict for the new data.\nWe know, to get higher chances of Admit\n* GRE: >310\n* TOEFL: >105\n* CGPA: >8.5\n* University Rating: >=4\n* Research: 1","metadata":{}},{"cell_type":"code","source":"#Test 1\nt1 = [319,107, 4, 4, 4, 8.1, 0]\n\nprint(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t1).reshape(1,-1))))\nprint(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t1).reshape(1,-1))))\nprint(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t1).reshape(1,-1))))","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:52.030076Z","iopub.execute_input":"2022-09-15T12:06:52.031013Z","iopub.status.idle":"2022-09-15T12:06:52.045590Z","shell.execute_reply.started":"2022-09-15T12:06:52.030969Z","shell.execute_reply":"2022-09-15T12:06:52.044333Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Linear Regression prediction:  [0.68449772]\nRandom Forest prediction:  [0.68449772]\nRidge prediction: [0.68527023]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Test2\nt2 = [319,107, 4, 4, 4, 8.7, 0]\n\nprint(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\nprint(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\nprint(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:52.048994Z","iopub.execute_input":"2022-09-15T12:06:52.049500Z","iopub.status.idle":"2022-09-15T12:06:52.064526Z","shell.execute_reply.started":"2022-09-15T12:06:52.049461Z","shell.execute_reply":"2022-09-15T12:06:52.062706Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Linear Regression prediction:  [0.75200375]\nRandom Forest prediction:  [0.75200375]\nRidge prediction: [0.75210039]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Test2\nt2 = [319,107, 4, 4, 4, 8.7, 1]\n\nprint(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\nprint(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\nprint(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:52.066559Z","iopub.execute_input":"2022-09-15T12:06:52.067178Z","iopub.status.idle":"2022-09-15T12:06:52.078151Z","shell.execute_reply.started":"2022-09-15T12:06:52.067140Z","shell.execute_reply":"2022-09-15T12:06:52.076670Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Linear Regression prediction:  [0.77703111]\nRandom Forest prediction:  [0.77703111]\nRidge prediction: [0.77712892]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Test2\nt2 = [319,107, 4, 4, 4, 9.4, 1]\n\nprint(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\nprint(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))\nprint(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t2).reshape(1,-1))))","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:52.080378Z","iopub.execute_input":"2022-09-15T12:06:52.081632Z","iopub.status.idle":"2022-09-15T12:06:52.097245Z","shell.execute_reply.started":"2022-09-15T12:06:52.081572Z","shell.execute_reply":"2022-09-15T12:06:52.094330Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Linear Regression prediction:  [0.85578814]\nRandom Forest prediction:  [0.85578814]\nRidge prediction: [0.85509744]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Lot of dependency on CGPA","metadata":{}},{"cell_type":"code","source":"#Test3\nt3 = [332,114, 5, 4, 4, 9.4, 1]\n\nprint(\"Linear Regression prediction: \", lr_model.predict(scaler.transform(np.array(t3).reshape(1,-1))))\nprint(\"Random Forest prediction: \", lr_model.predict(scaler.transform(np.array(t3).reshape(1,-1))))\nprint(\"Ridge prediction:\", ridge_model.predict(scaler.transform(np.array(t3).reshape(1,-1))))","metadata":{"execution":{"iopub.status.busy":"2022-09-15T12:06:52.099849Z","iopub.execute_input":"2022-09-15T12:06:52.101482Z","iopub.status.idle":"2022-09-15T12:06:52.114995Z","shell.execute_reply.started":"2022-09-15T12:06:52.101344Z","shell.execute_reply":"2022-09-15T12:06:52.113511Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Linear Regression prediction:  [0.90677949]\nRandom Forest prediction:  [0.90677949]\nRidge prediction: [0.90663372]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}